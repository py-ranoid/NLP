{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "def atisfold(fold):\n",
    "    assert fold in range(5)\n",
    "    f = PREFIX + 'atis.fold'+str(fold)+'.pkl'\n",
    "    train_set, valid_set, test_set, dicts = pickle.load(open(f, 'rb'), encoding='bytes')\n",
    "    return train_set, valid_set, test_set, dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'dataset/'\n",
    "w2ne, w2la = {}, {}\n",
    "train, _, test, dic = atisfold(1)\n",
    "w2idx, ne2idx, labels2idx = dic[b'words2idx'], dic[b'tables2idx'], dic[b'labels2idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'words2idx', b'tables2idx', b'labels2idx'])\n"
     ]
    }
   ],
   "source": [
    "print(dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'aircraft', 'is', 'used', 'on', 'delta', 'flight', 'DIGITDIGITDIGITDIGIT', 'from', 'kansas', 'city', 'to', 'salt', 'lake', 'city']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-airline_name', 'O', 'B-flight_number', 'O', 'B-fromloc.city_name', 'I-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name', 'I-toloc.city_name']\n",
      "\n",
      "['i', 'want', 'to', 'go', 'from', 'boston', 'to', 'atlanta', 'on', 'monday']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'O', 'B-depart_date.day_name']\n",
      "\n",
      "['i', 'need', 'a', 'flight', 'from', 'atlanta', 'to', 'philadelphia', 'and', 'i', \"'m\", 'looking', 'for', 'the', 'cheapest', 'fare']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'O', 'O', 'O', 'O', 'O', 'O', 'B-cost_relative', 'O']\n",
      "\n",
      "['i', 'need', 'a', 'flight', 'from', 'toronto', 'to', 'montreal', 'reaching', 'montreal', 'early', 'on', 'friday']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'O', 'B-toloc.city_name', 'B-arrive_time.period_mod', 'O', 'B-arrive_date.day_name']\n",
      "\n",
      "['show', 'me', 'the', 'evening', 'flights', 'from', 'philadelphia', 'to', 'baltimore']\n",
      "['O', 'O', 'O', 'B-depart_time.period_of_day', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name']\n",
      "\n",
      "['tell', 'me', 'distance', 'from', 'orlando', 'airport', 'to', 'the', 'city']\n",
      "['O', 'O', 'O', 'O', 'B-fromloc.airport_name', 'I-fromloc.airport_name', 'O', 'O', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_entities(labels):\n",
    "    idx = 0\n",
    "    last_begin = -1\n",
    "    entity = \"\"\n",
    "    entities = []\n",
    "    while idx < len(labels):\n",
    "        if labels[idx].startswith('B'):\n",
    "            last_begin = idx;\n",
    "            entity = labels[idx][2:]\n",
    "        elif labels[idx].startswith('O'):\n",
    "            if last_begin > 0:\n",
    "                entities.append((last_begin, idx, entity))\n",
    "                last_begin = -1\n",
    "        idx += 1\n",
    "    if last_begin > 0:\n",
    "        entities.append((last_begin, idx, entity))\n",
    "\n",
    "    return entities\n",
    "\n",
    "from mitie import *\n",
    "idx2w  = dict((v,k) for k,v in w2idx.items())\n",
    "idx2ne = dict((v,k) for k,v in ne2idx.items())\n",
    "idx2la = dict((v,k) for k,v in labels2idx.items())\n",
    "\n",
    "test_x,  test_ne,  test_label  = test\n",
    "train_x, train_ne, train_label = train\n",
    "trainer = ner_trainer(\"../MITIE-models/english/total_word_feature_extractor.dat\")\n",
    "\n",
    "output = 0\n",
    "for sentence_a, label_a in zip(train_x, train_label):\n",
    "    instance = [idx2w[word].decode('utf8') for word in sentence_a]\n",
    "    labels = [idx2la[label].decode('utf8') for label in label_a]\n",
    "    sample = ner_training_instance(instance)\n",
    "    print(instance)\n",
    "    print(labels)\n",
    "    print()\n",
    "    for entity in get_entities(labels):\n",
    "        sample.add_entity(xrange(entity[0], entity[1]), entity[2])\n",
    "    trainer.add(sample)\n",
    "    output += 1\n",
    "    if output > 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.num_threads = 4\n",
    "\n",
    "ner = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags: ['airline_name', 'flight_number', 'fromloc.city_name', 'toloc.city_name', 'depart_date.day_name', 'cost_relative', 'arrive_time.period_mod', 'arrive_date.day_name', 'depart_time.period_of_day', 'fromloc.airport_name']\n"
     ]
    }
   ],
   "source": [
    "print (\"tags:\", ner.get_possible_ner_tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence:  ['i', 'would', 'like', 'to', 'find', 'a', 'flight', 'from', 'charlotte', 'to', 'las', 'vegas', 'that', 'makes', 'a', 'stop', 'in', 'st.', 'louis']\n",
      "\n",
      "Test Label: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name', 'O', 'O', 'O', 'O', 'O', 'B-stoploc.city_name', 'I-stoploc.city_name']\n",
      "\n",
      "Entities found: [(range(2, 3), 'fromloc.city_name', 0.31079096411241164), (range(5, 6), 'depart_time.period_of_day', 0.14010175800500133), (range(8, 9), 'fromloc.city_name', 0.7084902255174335), (range(10, 12), 'toloc.city_name', 0.6191374784467214), (range(18, 19), 'toloc.city_name', 0.1356279520145114)]\n",
      "\n",
      "Test results: [(8, 9, 'fromloc.city_name'), (10, 12, 'toloc.city_name'), (17, 19, 'stoploc.city_name')]\n",
      "\n",
      "Number of entities detected: 5\n",
      "\n",
      "    fromloc.city_name: like\n",
      "    depart_time.period_of_day: a\n",
      "    fromloc.city_name: charlotte\n",
      "    toloc.city_name: las vegas\n",
      "    toloc.city_name: louis\n",
      "\n",
      "Sentence:  ['on', 'april', 'first', 'i', 'need', 'a', 'ticket', 'from', 'tacoma', 'to', 'san', 'jose', 'departing', 'before', 'DIGIT', 'am']\n",
      "\n",
      "Test Label: ['O', 'B-depart_date.month_name', 'B-depart_date.day_number', 'O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name', 'O', 'B-depart_time.time_relative', 'B-depart_time.time', 'I-depart_time.time']\n",
      "\n",
      "Entities found: [(range(1, 2), 'airline_name', 0.09472303363000832), (range(2, 3), 'fromloc.city_name', 0.047344724153692425), (range(8, 9), 'fromloc.city_name', 0.6040880783522227), (range(10, 11), 'toloc.city_name', 0.6122044514644109), (range(11, 12), 'toloc.city_name', 0.19388898940109342), (range(12, 13), 'toloc.city_name', 0.13750768289000725)]\n",
      "\n",
      "Test results: [(2, 3, 'depart_date.day_number'), (8, 9, 'fromloc.city_name'), (10, 12, 'toloc.city_name'), (14, 16, 'depart_time.time')]\n",
      "\n",
      "Number of entities detected: 6\n",
      "\n",
      "    airline_name: april\n",
      "    fromloc.city_name: first\n",
      "    fromloc.city_name: tacoma\n",
      "    toloc.city_name: san\n",
      "    toloc.city_name: jose\n",
      "    toloc.city_name: departing\n",
      "\n",
      "Sentence:  ['on', 'april', 'first', 'i', 'need', 'a', 'flight', 'going', 'from', 'phoenix', 'to', 'san', 'diego']\n",
      "\n",
      "Test Label: ['O', 'B-depart_date.month_name', 'B-depart_date.day_number', 'O', 'O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name']\n",
      "\n",
      "Entities found: [(range(1, 2), 'airline_name', 0.10879090628488232), (range(2, 3), 'fromloc.city_name', 0.04342171977330499), (range(9, 10), 'fromloc.city_name', 0.6386017880331303), (range(11, 13), 'toloc.city_name', 0.6385800709255386)]\n",
      "\n",
      "Test results: [(2, 3, 'depart_date.day_number'), (9, 10, 'fromloc.city_name'), (11, 13, 'toloc.city_name')]\n",
      "\n",
      "Number of entities detected: 4\n",
      "\n",
      "    airline_name: april\n",
      "    fromloc.city_name: first\n",
      "    fromloc.city_name: phoenix\n",
      "    toloc.city_name: san diego\n"
     ]
    }
   ],
   "source": [
    "output = 0\n",
    "for sentence_a, label_a in zip(test_x, test_label):\n",
    "    tokens = [idx2w[word].decode('utf8') for word in sentence_a]\n",
    "    labels = [idx2la[label].decode('utf8') for label in label_a]\n",
    "    entities = ner.extract_entities(tokens)\n",
    "    print (\"\\nSentence: \", tokens)\n",
    "    print (\"\\nTest Label:\", labels)\n",
    "    print (\"\\nEntities found:\", entities)\n",
    "    print (\"\\nTest results:\", get_entities(labels))\n",
    "    print (\"\\nNumber of entities detected:\", len(entities))\n",
    "    print ()\n",
    "    for e in entities:\n",
    "        range = e[0]\n",
    "        tag = e[1]\n",
    "        entity_text = \" \".join(tokens[i] for i in range)\n",
    "        print (\"    \" + tag + \": \" + entity_text)\n",
    "    output += 1\n",
    "    if output > 2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
