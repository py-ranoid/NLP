{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "def atisfold(fold):\n",
    "    assert fold in range(5)\n",
    "    f = PREFIX + 'atis.fold'+str(fold)+'.pkl'\n",
    "    train_set, valid_set, test_set, dicts = pickle.load(open(f, 'rb'), encoding='bytes')\n",
    "    return train_set, valid_set, test_set, dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'dataset/'\n",
    "w2ne, w2la = {}, {}\n",
    "train, _, test, dic = atisfold(1)\n",
    "w2idx, ne2idx, labels2idx = dic[b'words2idx'], dic[b'tables2idx'], dic[b'labels2idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'labels2idx', b'tables2idx', b'words2idx'])\n"
     ]
    }
   ],
   "source": [
    "print(dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'aircraft', 'is', 'used', 'on', 'delta', 'flight', 'DIGITDIGITDIGITDIGIT', 'from', 'kansas', 'city', 'to', 'salt', 'lake', 'city']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-airline_name', 'O', 'B-flight_number', 'O', 'B-fromloc.city_name', 'I-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name', 'I-toloc.city_name']\n",
      "\n",
      "['i', 'want', 'to', 'go', 'from', 'boston', 'to', 'atlanta', 'on', 'monday']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'O', 'B-depart_date.day_name']\n",
      "\n",
      "['i', 'need', 'a', 'flight', 'from', 'atlanta', 'to', 'philadelphia', 'and', 'i', \"'m\", 'looking', 'for', 'the', 'cheapest', 'fare']\n",
      "['O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'O', 'O', 'O', 'O', 'O', 'O', 'B-cost_relative', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from mitie import *\n",
    "idx2w  = dict((v,k) for k,v in w2idx.items())\n",
    "idx2ne = dict((v,k) for k,v in ne2idx.items())\n",
    "idx2la = dict((v,k) for k,v in labels2idx.items())\n",
    "\n",
    "test_x,  test_ne,  test_label  = test\n",
    "train_x, train_ne, train_label = train\n",
    "trainer = ner_trainer(\"../MITIE-models/english/total_word_feature_extractor.dat\")\n",
    "\n",
    "output = 0\n",
    "for sentence_a, label_a in zip(train_x, train_label):\n",
    "    instance = [idx2w[word].decode('utf8') for word in sentence_a]\n",
    "    labels = [idx2la[label].decode('utf8') for label in label_a]\n",
    "    sample = ner_training_instance(instance)\n",
    "    print(instance)\n",
    "    print(labels)\n",
    "    print()\n",
    "    idx = 0\n",
    "    last_begin = -1\n",
    "    entity = \"\"\n",
    "    while idx < len(labels):\n",
    "        if labels[idx].startswith('B'):\n",
    "            last_begin = idx;\n",
    "            entity = labels[idx][2:]\n",
    "        elif labels[idx].startswith('O'):\n",
    "            if last_begin > 0:\n",
    "                sample.add_entity(xrange(last_begin, idx), entity)\n",
    "                last_begin = -1\n",
    "        idx += 1\n",
    "    if last_begin > 0:\n",
    "        sample.add_entity(xrange(last_begin, idx), entity)\n",
    "    trainer.add(sample)\n",
    "    output += 1\n",
    "    if output > 2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.num_threads = 4\n",
    "\n",
    "ner = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags: ['airline_name', 'flight_number', 'fromloc.city_name', 'toloc.city_name', 'depart_date.day_name', 'cost_relative']\n"
     ]
    }
   ],
   "source": [
    "print (\"tags:\", ner.get_possible_ner_tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entities found: [(range(5, 6), 'fromloc.city_name', 0.6331889743239222), (range(7, 8), 'toloc.city_name', 0.42296601666364264), (range(9, 10), 'toloc.city_name', 0.12189891205777652), (range(12, 13), 'depart_date.day_name', 0.3760252247693764)]\n",
      "\n",
      "Number of entities detected: 4\n",
      "    fromloc.city_name: toronto\n",
      "    toloc.city_name: montreal\n",
      "    toloc.city_name: montreal\n",
      "    depart_date.day_name: friday\n"
     ]
    }
   ],
   "source": [
    "tokens = ['i', 'need', 'a', 'flight', 'from', 'toronto', 'to', 'montreal', 'reaching', 'montreal', 'early', 'on', 'friday']\n",
    "entities = ner.extract_entities(tokens)\n",
    "\n",
    "print (\"\\nEntities found:\", entities)\n",
    "print (\"\\nNumber of entities detected:\", len(entities))\n",
    "for e in entities:\n",
    "    range = e[0]\n",
    "    tag = e[1]\n",
    "    entity_text = \" \".join(tokens[i] for i in range)\n",
    "    print (\"    \" + tag + \": \" + entity_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the MITIE tool output information.\n",
    "\n",
    "\n",
    "    Training to recognize 6 labels: 'airline_name', 'flight_number', 'fromloc.city_name', 'toloc.city_name', 'depart_date.day_name', 'cost_relative'\n",
    "    Part I: train segmenter\n",
    "    words in dictionary: 200000\n",
    "    num features: 271\n",
    "    now do training\n",
    "    C:           20\n",
    "    epsilon:     0.01\n",
    "    num threads: 4\n",
    "    cache size:  5\n",
    "    max iterations: 2000\n",
    "    loss per missed segment:  3\n",
    "    C: 20   loss: 3 \t0.428571\n",
    "    C: 35   loss: 3 \t0.428571\n",
    "    C: 20   loss: 4.5 \t0.428571\n",
    "    C: 5   loss: 3 \t0.428571\n",
    "    C: 20   loss: 1.5 \t0.428571\n",
    "    C: 21   loss: 3 \t0.428571\n",
    "    C: 20   loss: 3.1 \t0.428571\n",
    "    C: 19   loss: 3 \t0.428571\n",
    "    C: 20   loss: 3 \t0.428571\n",
    "    best C: 20\n",
    "    best loss: 3\n",
    "    num feats in chunker model: 4095\n",
    "    train: precision, recall, f1-score: 1 1 1 \n",
    "    Part I: elapsed time: 1 seconds.\n",
    "\n",
    "    Part II: train segment classifier\n",
    "    now do training\n",
    "    num training samples: 10\n",
    "    test on train: \n",
    "    1 0 0 0 0 0 \n",
    "    0 1 0 0 0 0 \n",
    "    0 0 3 0 0 0 \n",
    "    0 0 0 3 0 0 \n",
    "    0 0 0 0 1 0 \n",
    "    0 0 0 0 0 1 \n",
    "\n",
    "    overall accuracy: 1\n",
    "    Part II: elapsed time: 9 seconds.\n",
    "    df.number_of_classes(): 6\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
