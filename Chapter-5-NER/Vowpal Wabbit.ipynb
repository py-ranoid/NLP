{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vowpalwabbit import pyvw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an installation issue in vw. Refer to https://github.com/JohnLangford/vowpal_wabbit/issues/1021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dataset from CoNLL 2003 (using spacy code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _consume_os(tags):\n",
    "    ## reference: https://github.com/explosion/spaCy/blob/c7d53348d7c0474852dc5ebe5794f2816ef7eb01/spacy/gold.pyx\n",
    "    while tags and tags[0] == 'O':\n",
    "        yield tags.pop(0)\n",
    "\n",
    "\n",
    "def _consume_ent(tags):\n",
    "    if not tags:\n",
    "        return []\n",
    "    tag = tags.pop(0)\n",
    "    target_in = 'I' + tag[1:]\n",
    "    target_last = 'L' + tag[1:]\n",
    "    length = 1\n",
    "    while tags and tags[0] in {target_in, target_last}:\n",
    "        length += 1\n",
    "        tags.pop(0)\n",
    "    label = tag[2:]\n",
    "    if length == 1:\n",
    "        return ['U-' + label]\n",
    "    else:\n",
    "        start = 'B-' + label\n",
    "        end = 'L-' + label\n",
    "        middle = ['I-%s' % label for _ in range(1, length - 1)]\n",
    "        return [start] + middle + [end]\n",
    "    \n",
    "def iob_to_biluo(tags):\n",
    "    out = []\n",
    "    curr_label = None\n",
    "    tags = list(tags)\n",
    "    while tags:\n",
    "        out.extend(_consume_os(tags))\n",
    "        out.extend(_consume_ent(tags))\n",
    "    return out\n",
    "\n",
    "def read_conll_ner(input_path):\n",
    "    ## reference: https://github.com/explosion/spaCy/blob/master/spacy/cli/converters/conll_ner2json.py\n",
    "    text = open(input_path,'r', encoding='utf-8').read()\n",
    "    i = 0\n",
    "    delimit_docs = '-DOCSTART- -X- O O'\n",
    "    output_docs = []\n",
    "    for doc in text.strip().split(delimit_docs):\n",
    "        doc = doc.strip()\n",
    "        if not doc:\n",
    "            continue\n",
    "        output_doc = []\n",
    "        for sent in doc.split('\\n\\n'):\n",
    "            sent = sent.strip()\n",
    "            if not sent:\n",
    "                continue\n",
    "            lines = [line.strip() for line in sent.split('\\n') if line.strip()]\n",
    "            words, tags, chunks, iob_ents = zip(*[line.split() for line in lines])\n",
    "            biluo_ents = iob_to_biluo(iob_ents)\n",
    "            output_doc.append({'tokens': [\n",
    "                {'orth': w, 'tag': tag, 'ner': ent} for (w, tag, ent) in\n",
    "                zip(words, tags, biluo_ents)\n",
    "            ]})\n",
    "        output_docs.append({\n",
    "            'id': len(output_docs),\n",
    "            'paragraphs': [{'sentences': output_doc}]\n",
    "        })\n",
    "        output_doc = []\n",
    "    return output_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(read_conll_ner('CoNLL - 2003/en/test.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is a basic implementation of sequence labeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceLabeler(pyvw.SearchTask):\n",
    "    def __init__(self, vw, sch, num_actions):\n",
    "        # you must must must initialize the parent class\n",
    "        # this will automatically store self.sch <- sch, self.vw <- vw\n",
    "        pyvw.SearchTask.__init__(self, vw, sch, num_actions)\n",
    "        \n",
    "        # set whatever options you want\n",
    "        sch.set_options( sch.AUTO_HAMMING_LOSS | sch.AUTO_CONDITION_FEATURES )\n",
    "\n",
    "    def _run(self, sentence):   # it's called _run to remind you that you shouldn't call it directly!\n",
    "        output = []\n",
    "        for n in range(len(sentence)):\n",
    "            pos,word = sentence[n]\n",
    "            # use \"with...as...\" to guarantee that the example is finished properly\n",
    "            with self.vw.example({'w': [word]}) as ex:\n",
    "                pred = self.sch.predict(examples=ex, my_tag=n+1, oracle=pos, condition=[(n,'p'), (n-1, 'q')])\n",
    "                output.append(pred)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vw = pyvw.vw(\"--search 4 --audit --quiet --search_task hook --ring_size 1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenceLabeler = vw.init_search_task(SequenceLabeler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    sequenceLabeler.learn(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example = [ (0,w) for w in \"the sandwich ate a monster\".split() ]\n",
    "print(test_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = sequenceLabeler.predict(test_example)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
