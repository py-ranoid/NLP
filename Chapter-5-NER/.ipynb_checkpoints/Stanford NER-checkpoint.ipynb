{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original stanfordcorenlp python wrapper source code version\n",
    "# doesn't has relation annotator from corenlp, so I added it in my code\n",
    "# !pip install stanfordcorenlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My forked corenlp python wrapper with relation support installation (testing)\n",
    "```bash\n",
    "pip uninstall stanfordcorenlp\n",
    "git clone https://github.com/suisuiwudi/stanford-corenlp\n",
    "cd stanford-corenlp\n",
    "python setup.py bdist_wheel --universal\n",
    "pip install dist/stanfordcorenlp-*.whl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "nlp = StanfordCoreNLP('../stanford-corenlp-full-2018-02-27') \n",
    "# this server needs root to run notebook server while running\n",
    "# ex. sudo jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize: ['Guangdong', 'University', 'of', 'Foreign', 'Studies', 'is', 'located', 'in', 'Guangzhou', '.']\n",
      "Part of Speech: [('Guangdong', 'NNP'), ('University', 'NNP'), ('of', 'IN'), ('Foreign', 'NNP'), ('Studies', 'NNPS'), ('is', 'VBZ'), ('located', 'JJ'), ('in', 'IN'), ('Guangzhou', 'NNP'), ('.', '.')]\n",
      "Named Entities: [('Guangdong', 'ORGANIZATION'), ('University', 'ORGANIZATION'), ('of', 'ORGANIZATION'), ('Foreign', 'ORGANIZATION'), ('Studies', 'ORGANIZATION'), ('is', 'O'), ('located', 'O'), ('in', 'O'), ('Guangzhou', 'CITY'), ('.', 'O')]\n",
      "Constituency Parsing: (ROOT\n",
      "  (S\n",
      "    (NP\n",
      "      (NP (NNP Guangdong) (NNP University))\n",
      "      (PP (IN of)\n",
      "        (NP (NNP Foreign) (NNPS Studies))))\n",
      "    (VP (VBZ is)\n",
      "      (ADJP (JJ located)\n",
      "        (PP (IN in)\n",
      "          (NP (NNP Guangzhou)))))\n",
      "    (. .)))\n",
      "Dependency Parsing: [('ROOT', 0, 7), ('compound', 2, 1), ('nsubjpass', 7, 2), ('case', 5, 3), ('compound', 5, 4), ('nmod', 2, 5), ('auxpass', 7, 6), ('case', 9, 8), ('nmod', 7, 9), ('punct', 7, 10)]\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Guangdong University of Foreign Studies is located in Guangzhou.'\n",
    "print('Tokenize:', nlp.word_tokenize(sentence))\n",
    "print('Part of Speech:', nlp.pos_tag(sentence))\n",
    "print('Named Entities:', nlp.ner(sentence))\n",
    "print('Constituency Parsing:', nlp.parse(sentence))\n",
    "print('Dependency Parsing:', nlp.dependency_parse(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dataset from CoNLL 2003 (using spacy code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _consume_os(tags):\n",
    "    ## reference: https://github.com/explosion/spaCy/blob/c7d53348d7c0474852dc5ebe5794f2816ef7eb01/spacy/gold.pyx\n",
    "    while tags and tags[0] == 'O':\n",
    "        yield tags.pop(0)\n",
    "\n",
    "\n",
    "def _consume_ent(tags):\n",
    "    if not tags:\n",
    "        return []\n",
    "    tag = tags.pop(0)\n",
    "    target_in = 'I' + tag[1:]\n",
    "    target_last = 'L' + tag[1:]\n",
    "    length = 1\n",
    "    while tags and tags[0] in {target_in, target_last}:\n",
    "        length += 1\n",
    "        tags.pop(0)\n",
    "    label = tag[2:]\n",
    "    if length == 1:\n",
    "        return ['U-' + label]\n",
    "    else:\n",
    "        start = 'B-' + label\n",
    "        end = 'L-' + label\n",
    "        middle = ['I-%s' % label for _ in range(1, length - 1)]\n",
    "        return [start] + middle + [end]\n",
    "    \n",
    "def iob_to_biluo(tags):\n",
    "    out = []\n",
    "    curr_label = None\n",
    "    tags = list(tags)\n",
    "    while tags:\n",
    "        out.extend(_consume_os(tags))\n",
    "        out.extend(_consume_ent(tags))\n",
    "    return out\n",
    "\n",
    "def read_conll_ner(input_path):\n",
    "    ## reference: https://github.com/explosion/spaCy/blob/master/spacy/cli/converters/conll_ner2json.py\n",
    "    text = open(input_path,'r', encoding='utf-8').read()\n",
    "    i = 0\n",
    "    delimit_docs = '-DOCSTART- -X- O O'\n",
    "    output_docs = []\n",
    "    for doc in text.strip().split(delimit_docs):\n",
    "        doc = doc.strip()\n",
    "        if not doc:\n",
    "            continue\n",
    "        output_doc = []\n",
    "        for sent in doc.split('\\n\\n'):\n",
    "            sent = sent.strip()\n",
    "            if not sent:\n",
    "                continue\n",
    "            lines = [line.strip() for line in sent.split('\\n') if line.strip()]\n",
    "            words, tags, chunks, iob_ents = zip(*[line.split() for line in lines])\n",
    "            biluo_ents = iob_to_biluo(iob_ents)\n",
    "            output_doc.append({'tokens': [\n",
    "                {'orth': w, 'tag': tag, 'ner': ent} for (w, tag, ent) in\n",
    "                zip(words, tags, biluo_ents)\n",
    "            ]})\n",
    "        output_docs.append({\n",
    "            'id': len(output_docs),\n",
    "            'paragraphs': [{'sentences': output_doc}]\n",
    "        })\n",
    "        output_doc = []\n",
    "    return output_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = read_conll_ner('CoNLL - 2003/en/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': [{'ner': 'O', 'tag': 'NN', 'orth': 'SOCCER'}, {'ner': 'O', 'tag': ':', 'orth': '-'}, {'ner': 'U-LOC', 'tag': 'NNP', 'orth': 'JAPAN'}, {'ner': 'O', 'tag': 'VB', 'orth': 'GET'}, {'ner': 'O', 'tag': 'NNP', 'orth': 'LUCKY'}, {'ner': 'O', 'tag': 'NNP', 'orth': 'WIN'}, {'ner': 'O', 'tag': ',', 'orth': ','}, {'ner': 'U-PER', 'tag': 'NNP', 'orth': 'CHINA'}, {'ner': 'O', 'tag': 'IN', 'orth': 'IN'}, {'ner': 'O', 'tag': 'DT', 'orth': 'SURPRISE'}, {'ner': 'O', 'tag': 'NN', 'orth': 'DEFEAT'}, {'ner': 'O', 'tag': '.', 'orth': '.'}]}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0]['paragraphs'][0]['sentences'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract fisrt sentence from test CoNLL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token['orth'] for token in test_data[0]['paragraphs'][0]['sentences'][1]['tokens']]\n",
    "sentence = ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part of Speech: [('SOCCER', 'NN'), ('-', ':'), ('JAPAN', 'NNP'), ('GET', 'VBP'), ('LUCKY', 'JJ'), ('WIN', 'NN'), (',', ','), ('CHINA', 'NNP'), ('IN', 'IN'), ('SURPRISE', 'NNP'), ('DEFEAT', 'NNP'), ('.', '.')]\n",
      "Named Entities: [('SOCCER', 'O'), ('-', 'O'), ('JAPAN', 'COUNTRY'), ('GET', 'O'), ('LUCKY', 'O'), ('WIN', 'O'), (',', 'O'), ('CHINA', 'COUNTRY'), ('IN', 'O'), ('SURPRISE', 'O'), ('DEFEAT', 'O'), ('.', 'O')]\n",
      "Constituency Parsing: (ROOT\n",
      "  (FRAG\n",
      "    (NP (NN SOCCER))\n",
      "    (: -)\n",
      "    (S\n",
      "      (NP (NNP JAPAN))\n",
      "      (VP (VBP GET)\n",
      "        (NP\n",
      "          (NP (JJ LUCKY) (NN WIN))\n",
      "          (, ,)\n",
      "          (NP\n",
      "            (NP (NNP CHINA))\n",
      "            (PP (IN IN)\n",
      "              (NP (NNP SURPRISE) (NNP DEFEAT)))))))\n",
      "    (. .)))\n",
      "Dependency Parsing: [('ROOT', 0, 1), ('punct', 1, 2), ('nsubj', 4, 3), ('dep', 1, 4), ('amod', 6, 5), ('dobj', 4, 6), ('punct', 4, 7), ('dep', 4, 8), ('case', 11, 9), ('compound', 11, 10), ('nmod', 8, 11), ('punct', 1, 12)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Part of Speech:', nlp.pos_tag(sentence))\n",
    "print('Named Entities:', nlp.ner(sentence))\n",
    "print('Constituency Parsing:', nlp.parse(sentence))\n",
    "print('Dependency Parsing:', nlp.dependency_parse(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation Extractor: {'sentences': [{'enhancedDependencies': [{'dependentGloss': 'SOCCER', 'dep': 'ROOT', 'dependent': 1, 'governorGloss': 'ROOT', 'governor': 0}, {'dependentGloss': '-', 'dep': 'punct', 'dependent': 2, 'governorGloss': 'SOCCER', 'governor': 1}, {'dependentGloss': 'JAPAN', 'dep': 'nsubj', 'dependent': 3, 'governorGloss': 'GET', 'governor': 4}, {'dependentGloss': 'GET', 'dep': 'appos', 'dependent': 4, 'governorGloss': 'SOCCER', 'governor': 1}, {'dependentGloss': 'LUCKY', 'dep': 'amod', 'dependent': 5, 'governorGloss': 'WIN', 'governor': 6}, {'dependentGloss': 'WIN', 'dep': 'dobj', 'dependent': 6, 'governorGloss': 'GET', 'governor': 4}, {'dependentGloss': ',', 'dep': 'punct', 'dependent': 7, 'governorGloss': 'WIN', 'governor': 6}, {'dependentGloss': 'CHINA', 'dep': 'appos', 'dependent': 8, 'governorGloss': 'WIN', 'governor': 6}, {'dependentGloss': 'IN', 'dep': 'case', 'dependent': 9, 'governorGloss': 'DEFEAT', 'governor': 11}, {'dependentGloss': 'SURPRISE', 'dep': 'compound', 'dependent': 10, 'governorGloss': 'DEFEAT', 'governor': 11}, {'dependentGloss': 'DEFEAT', 'dep': 'nmod:in', 'dependent': 11, 'governorGloss': 'CHINA', 'governor': 8}, {'dependentGloss': '.', 'dep': 'punct', 'dependent': 12, 'governorGloss': 'SOCCER', 'governor': 1}], 'tokens': [{'characterOffsetEnd': 6, 'ner': 'O', 'after': ' ', 'word': 'SOCCER', 'pos': 'NN', 'index': 1, 'lemma': 'soccer', 'originalText': 'SOCCER', 'before': '', 'characterOffsetBegin': 0}, {'characterOffsetEnd': 8, 'ner': 'O', 'after': ' ', 'word': '-', 'pos': ':', 'index': 2, 'lemma': '-', 'originalText': '-', 'before': ' ', 'characterOffsetBegin': 7}, {'characterOffsetEnd': 14, 'ner': 'COUNTRY', 'after': ' ', 'word': 'JAPAN', 'pos': 'NNP', 'index': 3, 'lemma': 'JAPAN', 'originalText': 'JAPAN', 'before': ' ', 'characterOffsetBegin': 9}, {'characterOffsetEnd': 18, 'ner': 'O', 'after': ' ', 'word': 'GET', 'pos': 'VBP', 'index': 4, 'lemma': 'get', 'originalText': 'GET', 'before': ' ', 'characterOffsetBegin': 15}, {'characterOffsetEnd': 24, 'ner': 'O', 'after': ' ', 'word': 'LUCKY', 'pos': 'JJ', 'index': 5, 'lemma': 'lucky', 'originalText': 'LUCKY', 'before': ' ', 'characterOffsetBegin': 19}, {'characterOffsetEnd': 28, 'ner': 'O', 'after': ' ', 'word': 'WIN', 'pos': 'NN', 'index': 6, 'lemma': 'win', 'originalText': 'WIN', 'before': ' ', 'characterOffsetBegin': 25}, {'characterOffsetEnd': 30, 'ner': 'O', 'after': ' ', 'word': ',', 'pos': ',', 'index': 7, 'lemma': ',', 'originalText': ',', 'before': ' ', 'characterOffsetBegin': 29}, {'characterOffsetEnd': 36, 'ner': 'COUNTRY', 'after': ' ', 'word': 'CHINA', 'pos': 'NNP', 'index': 8, 'lemma': 'CHINA', 'originalText': 'CHINA', 'before': ' ', 'characterOffsetBegin': 31}, {'characterOffsetEnd': 39, 'ner': 'O', 'after': ' ', 'word': 'IN', 'pos': 'IN', 'index': 9, 'lemma': 'in', 'originalText': 'IN', 'before': ' ', 'characterOffsetBegin': 37}, {'characterOffsetEnd': 48, 'ner': 'O', 'after': ' ', 'word': 'SURPRISE', 'pos': 'NNP', 'index': 10, 'lemma': 'SURPRISE', 'originalText': 'SURPRISE', 'before': ' ', 'characterOffsetBegin': 40}, {'characterOffsetEnd': 55, 'ner': 'O', 'after': ' ', 'word': 'DEFEAT', 'pos': 'NNP', 'index': 11, 'lemma': 'DEFEAT', 'originalText': 'DEFEAT', 'before': ' ', 'characterOffsetBegin': 49}, {'characterOffsetEnd': 57, 'ner': 'O', 'after': '', 'word': '.', 'pos': '.', 'index': 12, 'lemma': '.', 'originalText': '.', 'before': ' ', 'characterOffsetBegin': 56}], 'basicDependencies': [{'dependentGloss': 'SOCCER', 'dep': 'ROOT', 'dependent': 1, 'governorGloss': 'ROOT', 'governor': 0}, {'dependentGloss': '-', 'dep': 'punct', 'dependent': 2, 'governorGloss': 'SOCCER', 'governor': 1}, {'dependentGloss': 'JAPAN', 'dep': 'nsubj', 'dependent': 3, 'governorGloss': 'GET', 'governor': 4}, {'dependentGloss': 'GET', 'dep': 'appos', 'dependent': 4, 'governorGloss': 'SOCCER', 'governor': 1}, {'dependentGloss': 'LUCKY', 'dep': 'amod', 'dependent': 5, 'governorGloss': 'WIN', 'governor': 6}, {'dependentGloss': 'WIN', 'dep': 'dobj', 'dependent': 6, 'governorGloss': 'GET', 'governor': 4}, {'dependentGloss': ',', 'dep': 'punct', 'dependent': 7, 'governorGloss': 'WIN', 'governor': 6}, {'dependentGloss': 'CHINA', 'dep': 'appos', 'dependent': 8, 'governorGloss': 'WIN', 'governor': 6}, {'dependentGloss': 'IN', 'dep': 'case', 'dependent': 9, 'governorGloss': 'DEFEAT', 'governor': 11}, {'dependentGloss': 'SURPRISE', 'dep': 'compound', 'dependent': 10, 'governorGloss': 'DEFEAT', 'governor': 11}, {'dependentGloss': 'DEFEAT', 'dep': 'nmod', 'dependent': 11, 'governorGloss': 'CHINA', 'governor': 8}, {'dependentGloss': '.', 'dep': 'punct', 'dependent': 12, 'governorGloss': 'SOCCER', 'governor': 1}], 'parse': '(ROOT\\n  (FRAG\\n    (NP (NN SOCCER))\\n    (: -)\\n    (S\\n      (NP (NNP JAPAN))\\n      (VP (VBP GET)\\n        (NP\\n          (NP (JJ LUCKY) (NN WIN))\\n          (, ,)\\n          (NP\\n            (NP (NNP CHINA))\\n            (PP (IN IN)\\n              (NP (NNP SURPRISE) (NNP DEFEAT)))))))\\n    (. .)))', 'index': 0, 'entitymentions': [{'docTokenEnd': 3, 'characterOffsetEnd': 14, 'docTokenBegin': 2, 'ner': 'COUNTRY', 'tokenEnd': 3, 'text': 'JAPAN', 'tokenBegin': 2, 'characterOffsetBegin': 9}, {'docTokenEnd': 8, 'characterOffsetEnd': 36, 'docTokenBegin': 7, 'ner': 'COUNTRY', 'tokenEnd': 8, 'text': 'CHINA', 'tokenBegin': 7, 'characterOffsetBegin': 31}], 'enhancedPlusPlusDependencies': [{'dependentGloss': 'SOCCER', 'dep': 'ROOT', 'dependent': 1, 'governorGloss': 'ROOT', 'governor': 0}, {'dependentGloss': '-', 'dep': 'punct', 'dependent': 2, 'governorGloss': 'SOCCER', 'governor': 1}, {'dependentGloss': 'JAPAN', 'dep': 'nsubj', 'dependent': 3, 'governorGloss': 'GET', 'governor': 4}, {'dependentGloss': 'GET', 'dep': 'appos', 'dependent': 4, 'governorGloss': 'SOCCER', 'governor': 1}, {'dependentGloss': 'LUCKY', 'dep': 'amod', 'dependent': 5, 'governorGloss': 'WIN', 'governor': 6}, {'dependentGloss': 'WIN', 'dep': 'dobj', 'dependent': 6, 'governorGloss': 'GET', 'governor': 4}, {'dependentGloss': ',', 'dep': 'punct', 'dependent': 7, 'governorGloss': 'WIN', 'governor': 6}, {'dependentGloss': 'CHINA', 'dep': 'appos', 'dependent': 8, 'governorGloss': 'WIN', 'governor': 6}, {'dependentGloss': 'IN', 'dep': 'case', 'dependent': 9, 'governorGloss': 'DEFEAT', 'governor': 11}, {'dependentGloss': 'SURPRISE', 'dep': 'compound', 'dependent': 10, 'governorGloss': 'DEFEAT', 'governor': 11}, {'dependentGloss': 'DEFEAT', 'dep': 'nmod:in', 'dependent': 11, 'governorGloss': 'CHINA', 'governor': 8}, {'dependentGloss': '.', 'dep': 'punct', 'dependent': 12, 'governorGloss': 'SOCCER', 'governor': 1}]}]}\n"
     ]
    }
   ],
   "source": [
    "print('Relation Extractor:', nlp.relation(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm still need to figure out how ot print the relation extractor from corenlp java server."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
