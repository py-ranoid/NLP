{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wn(tag):\n",
    "    \"\"\" \n",
    "        Convert between a Penn Treebank tag to a simplified Wordnet tag \n",
    "    \"\"\"\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    "\n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    "\n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    "\n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    "\n",
    "    return None\n",
    " \n",
    "def tagged_to_synset(word, tag):\n",
    "    \n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag is None:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        return wn.synsets(word, wn_tag)[0]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def sentence_similarity(sentence1, sentence2):\n",
    "    \"\"\" \n",
    "        reference: https://nlpforhackers.io/wordnet-sentence-similarity/\n",
    "        compute the sentence similarity using Wordnet \n",
    "    \"\"\"\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2))\n",
    "    # Get the synsets for the tagged words\n",
    "\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    "    \n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    "    \n",
    "    score, count = 0.0, 0\n",
    "\n",
    "    # For each word in the first sentence\n",
    "    for synset in synsets1:\n",
    "        # Get the similarity value of the most similar word in the other sentence\n",
    "        scores = [synset.path_similarity(ss) for ss in synsets2]\n",
    "        scores = [ss for ss in scores if ss]\n",
    "        if len(scores) > 0:\n",
    "            best_score = max(scores)\n",
    "            score += best_score\n",
    "            count += 1\n",
    "            \n",
    "    # Average the values\n",
    "    if count != 0:\n",
    "        score /= count\n",
    "        return score\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def symmetric_sentence_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the symmetric sentence similarity using Wordnet \"\"\"\n",
    "    return (sentence_similarity(sentence1, sentence2) + sentence_similarity(sentence2, sentence1)) / 2 \n",
    "\n",
    "class MyCompleter(object):  # Custom completer\n",
    "\n",
    "    def __init__(self, options):\n",
    "        self.freq = {}\n",
    "        self.add(options)\n",
    "        \n",
    "    def add(self, options):\n",
    "        for word in options:\n",
    "            if word not in self.freq:\n",
    "                self.freq[word] = 1\n",
    "            else:\n",
    "                self.freq[word] = self.freq[word] + 1\n",
    "                \n",
    "    def complete_frequency(self, text, k):\n",
    "        if text:  # cache matches (entries that start with entered text)\n",
    "            self.matches = [(key,value) for (key,value) in self.freq.items()\n",
    "                                if key and key.startswith(text)]\n",
    "        \n",
    "        sorted_d = sorted(self.matches, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        if len(self.matches) > k:\n",
    "            sorted_d = sorted_d[:k]\n",
    "            \n",
    "        # the output is sorted in frequency, it depends on corpus or user, we could set more weight on words which user used \n",
    "        return [key for (key,value) in sorted_d]\n",
    "    \n",
    "\n",
    "    \n",
    "    def complete_similarity(self, text, k):\n",
    "        if text:  # cache matches (entries that start with entered text)\n",
    "            self.matches = [(key, value, symmetric_sentence_similarity(key, text)) for (key,value) in self.freq.items()]\n",
    "       \n",
    "        print(self.matches)\n",
    "        sorted_d = sorted(self.matches, key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        if len(self.matches) > k:\n",
    "            sorted_d = sorted_d[:k]\n",
    "        return [key for (key, value, score) in sorted_d]\n",
    "    \n",
    "    \n",
    "completer = MyCompleter([\"hello\", \"hi\", \"hi\", \"how\", \"goodbye\", \"great\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'hello']\n",
      "[('hello', 1, 0.6549075924075924), ('hi', 2, 0.6549075924075924), ('how', 1, 0.0), ('goodbye', 1, 0.15490759240759241), ('great', 1, 0.0), ('Hello Mr. Jade, how are you', 1, 0.7795138888888888)]\n",
      "['Hello Mr. Jade, how are you']\n",
      "[('hello', 1, 0.6946386946386947), ('hi', 2, 0.6946386946386947), ('how', 1, 0.0), ('goodbye', 1, 0.16130536130536133), ('great', 1, 0.0), ('Hello Mr. Jade, how are you', 1, 0.6313657407407407)]\n",
      "['hello']\n"
     ]
    }
   ],
   "source": [
    "# get result from \n",
    "print(completer.complete_frequency(\"h\",2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7795138888888888\n"
     ]
    }
   ],
   "source": [
    "completer.add([\"Hello Mr. Jade, how are you\"])\n",
    "print(completer.complete_similarity(\"Hello Mr. Jade, h\", 1))\n",
    "print(completer.complete_similarity(\"Hello Mr. Joe, h\", 1))\n",
    "print(symmetric_sentence_similarity(\"Hello Mr. Jade, how are you\", \"Hello Mr. Jade, h\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
